<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> From Science Fiction to Reality The AI Revolution from Neural Networks to GPT | Anupam Jose </title> <meta name="author" content="Anupam Jose "> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ajcobraa.github.io/blog/2025/aievolution/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Anupam Jose</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">From Science Fiction to Reality The AI Revolution from Neural Networks to GPT</h1> <p class="post-meta"> Created on March 24, 2025 by Anupam Jose </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ai-evolution"> <i class="fa-solid fa-hashtag fa-sm"></i> AI-Evolution</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="early-neural-networks-and-backpropagation-1980s">Early Neural Networks and Backpropagation (1980s):</h2> <p>The concept of artificial neural networks (ANNs) dates back to the mid-20th century. Early models like Frank Rosenblatt’s perceptron (1958) could learn simple patterns, but they were limited in scope. In 1969, Marvin Minsky and Seymour Papert published Perceptrons, highlighting that single-layer networks can only learn linearly separable functions, which caused a decline in neural network research in the 1970s​ <a href="https://www.techtarget.com/whatis/feature/History-and-evolution-of-machine-learning-A-timeline#:~:text=for%20deep%20learning" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">techttarget</code></a> . The field rebounded in the 1980s with the introduction of the backpropagation algorithm (pioneered by Rumelhart, Hinton, Williams, and others). Backpropagation enabled efficient training of multi-layer networks (i.e. networks with “hidden” layers), an advancement over the single-layer perceptron and a foundational breakthrough for deep learning​ . This meant ANNs could now learn much more complex mappings from inputs to outputs. However, training these early networks was computationally expensive and often limited by the hardware and data available at the time, so practical impact remained modest until later.</p> <pre><code class="language-mermaid">flowchart TD
    subgraph Input_Layer
        I1[Input 1]
        I2[Input 2]
        I3[Input 3]
    end

    subgraph Hidden_Layer
        H1[Hidden 1]
        H2[Hidden 2]
        H3[Hidden 3]
    end

    subgraph Output_Layer
        O1[Output 1]
        O2[Output 2]
    end

    I1 --&gt; H1
    I1 --&gt; H2
    I1 --&gt; H3
    I2 --&gt; H1
    I2 --&gt; H2
    I2 --&gt; H3
    I3 --&gt; H1
    I3 --&gt; H2
    I3 --&gt; H3

    H1 --&gt; O1
    H1 --&gt; O2
    H2 --&gt; O1
    H2 --&gt; O2
    H3 --&gt; O1
    H3 --&gt; O2
</code></pre> <hr> <h2 id="recurrent-neural-networks-and-long-term-dependencies-1990s">Recurrent Neural Networks and Long-Term Dependencies (1990s)</h2> <p>As researchers explored new architectures, they developed Recurrent Neural Networks (<a href="https://arxiv.org/abs/1912.05911" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">RNNs</code></a>) to handle sequential data (like time series and language). RNNs introduce feedback loops so that past outputs can influence future inputs, giving the network a form of memory. In theory this allowed modeling long-term dependencies, but in practice RNNs were very hard to train on long sequences due to the vanishing gradient problem: as errors were back-propagated through many time steps, the gradient values would shrink exponentially, preventing the network from learning long-range correlations​. In the mid-1990s, this limitation was addressed by the invention of the Long Short-Term Memory (LSTM) network (Hochreiter &amp; Schmidhuber, 1997). LSTM introduced gating mechanisms that let the network decide what to keep or forget, enabling it to preserve information over hundreds or thousands of time steps​. This was a major breakthrough for sequence learning – LSTMs overcame vanishing gradients and soon “set accuracy records in multiple application domains”, becoming the default RNN architecture for tasks like speech recognition​ <a href="https://en.wikipedia.org/wiki/History_of_artificial_neural_networks#Recurrent_network_architectures#:~:text=Long%20short,default%20choice%20for%20RNN%20architecture" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">Wikipedia</code></a> . Thanks to LSTM (and later, the simplified GRU variant), RNNs in the 2000s could learn long-term patterns in text, audio, and other sequence data that vanilla RNNs could not.</p> <hr> <h2 id="convolutional-neural-networks-and-the-deep-learning-boom-2010s">Convolutional Neural Networks and the Deep Learning Boom (2010s)</h2> <p>Early vs. modern convolutional networks: The diagram compares the 1990s LeNet-5 CNN (left) to the deeper 2012 AlexNet CNN (right), illustrating how neural networks grew in depth and complexity as more data and compute became available​ <a href="https://en.wikipedia.org/wiki/AlexNet#:~:text=While%20AlexNet%20and%20LeNet%20share,18" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">Wikipedia</code></a></p> <p>![Comparison of LeNet-5 and AlexNet architectures]<a href="https://upload.wikimedia.org/wikipedia/commons/c/cc/Comparison_image_neural_networks.svg.jpg" data-lightbox="roadtrip" rel="external nofollow noopener" target="_blank"><img src="https://upload.wikimedia.org/wikipedia/commons/c/cc/Comparison_image_neural_networks.svg"></a> “Diagram comparing the architectures of LeNet-5 (1998) and AlexNet (2012), showing the increase in depth and complexity.”</p> <p><em>Caption: A comparison of LeNet-5 (left) and AlexNet (right), highlighting the evolution of CNN architectures with increased depth and complexity in the 2010s.</em> . Convolutional Neural Networks (<a href="https://arxiv.org/abs/1511.08458" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">CNNs</code></a>) were designed to process grid-like data such as images. Inspired by the human visual cortex, CNNs use layers of convolution filters to automatically learn spatial hierarchies of features (edges, shapes, objects) from images. Early CNN work by Yann LeCun in the late 1980s demonstrated that neural nets could recognize handwritten characters (e.g. zip code digits) with high accuracy​. LeCun’s LeNet-5 (1998) is a landmark example, successfully reading handwritten digits. Despite these successes, throughout the 1990s and early 2000s neural networks often failed to outperform more hand-crafted approaches (like SVMs or decision trees) on complex tasks, and many in the research community were skeptical​. Two factors changed this: data and hardware. By the 2010s, much larger labeled datasets became available (e.g. the ImageNet database of millions of images), and graphics processing units (GPUs) allowed the training of bigger, deeper networks. In 2012, a deep CNN known as AlexNet (developed by Hinton, Krizhevsky, and Sutskever) won the ImageNet competition by a huge margin, beating the previous state-of-the-art in image recognition by a significant leap​. This triumph vividly showed the power of deep learning and “triggered an explosion of deep learning research and implementation” across the industry​ <a href="https://www.techtarget.com/whatis/feature/History-and-evolution-of-machine-learning-A-timeline#:~:text=2012" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">techttarget</code></a> . CNNs rapidly became the dominant approach for computer vision tasks – from object detection to facial recognition – and were soon achieving superhuman performance in some domains (e.g. recognizing traffic signs or diagnosing medical images). The success of AlexNet and subsequent CNN models (VGG, GoogLeNet, ResNet, etc.) marks the beginning of the modern deep learning era in AI.</p> <hr> <h2 id="generative-adversarial-networks-2014--generative-ai-breakthrough">Generative Adversarial Networks (2014) – Generative AI Breakthrough</h2> <p>As neural networks grew more capable, researchers began exploring models that generate new data rather than just recognize it. A milestone in this area was the introduction of Generative Adversarial Networks (GANs) in 2014 by Ian Goodfellow and colleagues​ <a href="https://arxiv.org/abs/1406.2661" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">GAN</code></a> . A GAN consists of two competing neural networks: a generator that tries to create realistic fake data (e.g. images that look like real photographs), and a discriminator that tries to tell apart the generator’s fakes from real data. The two networks are trained in tandem in a “adversarial” game: the generator improves at fooling the discriminator, and the discriminator gets better at spotting fakes. This clever setup enabled GANs to produce incredibly realistic images, noises, and other data. Over the 2014–2018 period, GANs became state-of-the-art in generative modeling​ <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">Wikipedia</code></a> – for example, NVIDIA’s StyleGAN (2018) could generate photorealistic human faces that don’t belong to any real person​ <a href="https://research.nvidia.com/publication/2022-05_stylegan-nada-clip-guided-domain-adaptation-image-generators" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">research.nvidia</code></a> . Researchers also built variants for tasks like image-to-image translation (e.g. turning sketches into color images) and video generation. The advent of GANs was significant because it showed neural networks could create – not just classify – complex data, opening the door to today’s generative AI applications (art creation, deepfakes, data augmentation, etc.). GANs did have their challenges (such as training instabilities like mode collapse), but they undeniably pushed the boundaries of what AI could do, and spurred a lot of excitement about generative AI.</p> <pre><code class="language-mermaid">stateDiagram-v2
    [*] --&gt; Noise
    Noise --&gt; Generator : Random Vector z
    Generator --&gt; Fake_Data : Generates Fake Samples
    Real_Data --&gt; Discriminator
    Fake_Data --&gt; Discriminator
    Discriminator --&gt; Decision : Real / Fake?
    Decision --&gt; Generator : Feedback (Loss)
    Decision --&gt; Discriminator : Feedback (Loss)
    Decision --&gt; [*]

    state Real_Data {
        direction LR
        Dataset --&gt; Sample
    }
</code></pre> <p>Explanation:</p> <p>Noise: Random input vector (z) fed to the Generator.</p> <p>Generator: Creates fake data samples from noise.</p> <p>Real_Data: Authentic samples from the real dataset.</p> <p>Discriminator: Classifies input samples as real or fake.</p> <p>Decision: Discriminator’s classification result.</p> <p>Feedback (Loss): Used to improve both Generator and Discriminator.</p> <hr> <p>Transformers – “Attention Is All You Need” (2017)</p> <p>In 2017, a single paper fundamentally altered the course of AI research. Google researchers Ashish Vaswani et al. published “Attention Is All You Need,” which introduced the Transformer architecture​ <a href="https://en.wikipedia.org/wiki/Attention_Is_All_You_Need#:~:text=,was%20on%20improving%20%2060" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">Wikipedia</code></a> . The Transformer was a radical departure from previous sequence models (like RNNs) because it did not use any recurrent loops or convolutions for processing sequences. Instead, it relied entirely on a mechanism called self-attention that allowed the model to weigh the influence of different input elements on each other. In essence, a Transformer can look at an entire sequence (say, a sentence) and learn which words or parts of the sequence are relevant to each other, and it can do this for all parts of the sequence in parallel​ <a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">Transformers</code></a> . By removing the sequential nature of RNNs, Transformers achieved two huge benefits: they preserved long-range context much more effectively (since even distant elements can directly attend to each other), and they could be parallelized during training, making it feasible to train very large models on GPUs or TPUs​ <a href="https://en.wikipedia.org/wiki/Attention_Is_All_You_Need#:~:text=The%20paper%20is%20most%20well,bigger%20sizes%20to%20be%20trained" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">Wikipedia</code></a> . The 2017 paper focused on machine translation, showing that Transformers outperformed RNN-based translation models and were faster to train​. But the authors correctly anticipated that the approach could be applied much more broadly​. Indeed, the Transformer architecture quickly became the new standard for natural language processing. It was modular (built from repeated self-attention and feed-forward layers) and scaled extremely well with data and compute. Almost overnight, researchers began replacing recurrent networks with Transformers in language tasks. The Transformer is now regarded as a “foundational” architecture in modern AI, forming the backbone of most large-scale models​. With Transformers, the stage was set for an era of unprecedented progress, as they enabled the training of models on unthinkably large datasets and for new capabilities.</p> <hr> <p>Large Language Models and Modern AI Explosion (2018–Present)</p> <p>The introduction of Transformers in 2017 ushered in a period of accelerating progress in AI. One of the first major fruits of this innovation was the rise of large language models (LLMs) built on the Transformer architecture. In 2018, OpenAI released the first Generative Pre-Trained Transformer model, known as GPT-1, demonstrating that a Transformer trained on massive amounts of text could generate fluent passages of natural language​ <a href="https://www.techtarget.com/whatis/feature/History-and-evolution-of-machine-learning-A-timeline#:~:text=2018" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">techttarget</code></a> . OpenAI’s approach was to pre-train the model on a diverse corpus (so it learned general language patterns) and then fine-tune it on specific tasks – a recipe that proved extremely powerful. The following year, they unveiled GPT-2 (2019), a significantly larger model with about 1.5 billion parameters​ <a href="https://en.wikipedia.org/wiki/GPT-3#:~:text=of%20manually,9" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">Wikipedia</code></a> . GPT-2 showed dramatic improvements in generating coherent and contextually relevant text, to the point of writing entire news articles or stories that were often hard to distinguish from human-written content. In 2020 came GPT-3, which was a quantum leap in scale: 175 billion parameters​ trained on nearly all of the Internet’s text. GPT-3 astonished the world with its ability to perform tasks it was never explicitly trained for (from writing code to answering complex questions) simply by being prompted with a few examples – so-called “few-shot” learning​ <a href="https://www.ibm.com/think/topics/few-shot-learning#:~:text=Few%2Dshot%20learning%20is%20a,suitable%20training%20data%20is%20scarce." rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">few-shot</code></a> . This demonstrated a surprising emergent capability: with enough data and parameters, a Transformer-based model could learn to do a wide range of tasks without specialized training for each one. Other organizations and researchers also quickly adopted Transformers to build their own large models. In late 2018 Google introduced BERT (Bidirectional Encoder Representations from Transformers), which used a Transformer encoder to achieve state-of-the-art results in language understanding tasks. Subsequent models like MegatronLM, T5, XLNet, and PALM pushed the envelope further in various ways (larger sizes, different training objectives, etc.). These models collectively are referred to as large language models, and they began to revolutionize language-based AI across the board – powering translation services, search engines, personal assistants, and more. A key turning point in public awareness was the release of ChatGPT by OpenAI in late 2022. ChatGPT took the GPT-3.5 model and fine-tuned it for conversational interaction, packaging it in an accessible chat interface. Within months, it reached over 100 million users, exposing millions of people to AI-generated text as a useful (and sometimes uncanny) tool in daily life​. Shortly after, in 2023, OpenAI announced GPT-4, a still larger and more advanced model that is multimodal (able to accept text and images as input) and exhibits even more advanced reasoning and understanding capabilities​. The pace at which these Transformer-based systems have improved is often described as exponential. In fact, the period from 2017 to 2025 has seen more rapid AI development than perhaps the entire 30 years prior – a testament to how impactful the Transformer innovation has been. Improved algorithms (the attention-based architectures), orders-of-magnitude more computing power, and unprecedented quantities of training data have together “fueled a revolution” in machine learning, resulting in rapid improvements on many tasks​. Today’s AI models can converse, answer questions, generate images, compose music, and more – achievements that would have been science fiction a decade ago. And this progress shows no sign of slowing down, all tracing back to those key milestones: from the early neural nets and CNNs, to GANs, and especially the game-changing introduction of Transformers in 2017 that truly transformed the evolution of AI.</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Anupam Jose . </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>